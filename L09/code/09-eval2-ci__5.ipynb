{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 451: Machine Learning (Fall 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat451-fs2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L09: Model Evaluation 2 -- Confidence Intervals and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Out-of-Bag Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to look at the OOB bootstrap method, which I recently implemented in mlxtend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 0 1 3] [2]\n",
      "[0 0 1 4 4] [2 3]\n",
      "[1 2 4 2 4] [0 3]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import BootstrapOutOfBag\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oob = BootstrapOutOfBag(n_splits=3, random_seed=1)\n",
    "for train, test in oob.split(np.array([1, 2, 3, 4, 5])):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why I chose a object-oriented implementation is that we can plug it into scikit-learn's `cross_val_score` function, which is super convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import iris_data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X, y = iris_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=123, stratify=y)\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are using the standard approach for `cross_val_score` first, which will perform 5-fold cross validation by setting `cv=5`. Note that \n",
    "\n",
    "- if the model is a scikit-learn classifier, stratified k-fold cross validation will be performed by default, and the reported evaluation metric is the prediction accuracy;\n",
    "- if the model is a scikit-learn regressor, standard k-fold cross validation will be performed by default, and the reported evaluation metric is the $R^2$ score on the test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores [0.94444444 1.         1.         0.88888889 0.94444444]\n",
      "Mean CV score 0.9555555555555555\n",
      "CV score Std 0.04157397096415492\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print('CV scores', cv_scores)\n",
    "print('Mean CV score', np.mean(cv_scores))\n",
    "print('CV score Std', np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plug in our OOB object into the `cross_val_score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap scores [0.93548387 0.96774194 0.96875    0.93023256 0.97058824]\n",
      "Mean Bootstrap score 0.9545593199770531\n",
      "Score Std 0.017819915677477555\n"
     ]
    }
   ],
   "source": [
    "# 5 splits\n",
    "\n",
    "bootstrap_scores = \\\n",
    "    cross_val_score(model, X_train, y_train, \n",
    "                    cv=BootstrapOutOfBag(n_splits=5, random_seed=123))\n",
    "\n",
    "print('Bootstrap scores', bootstrap_scores)\n",
    "print('Mean Bootstrap score', np.mean(bootstrap_scores))\n",
    "print('Score Std', np.std(bootstrap_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bootstrap score 0.9483980861793887\n",
      "Score Std 0.039817322453014004\n"
     ]
    }
   ],
   "source": [
    "bootstrap_scores = \\\n",
    "    cross_val_score(model, X_train, y_train, \n",
    "                    cv=BootstrapOutOfBag(n_splits=200, random_seed=123))\n",
    "\n",
    "print('Mean Bootstrap score', np.mean(bootstrap_scores))\n",
    "print('Score Std', np.std(bootstrap_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval: [83.33, 100.00]\n"
     ]
    }
   ],
   "source": [
    "lower = np.percentile(bootstrap_scores, 2.5)\n",
    "upper = np.percentile(bootstrap_scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLxtend functional bootstrap API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OOB Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a more convenient way to compute the OOB Boostrap. Note that it has a tendency to be over-pessimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bootstrap score 0.9483980861793887\n",
      "Score Std 0.039817322453014004\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "\n",
    "bootstrap_scores = bootstrap_point632_score(model, \n",
    "                                            X_train, y_train, \n",
    "                                            n_splits=200, \n",
    "                                            method='oob',\n",
    "                                            random_seed=123)\n",
    "\n",
    "print('Mean Bootstrap score', np.mean(bootstrap_scores))\n",
    "print('Score Std', np.std(bootstrap_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval: [83.33, 100.00]\n"
     ]
    }
   ],
   "source": [
    "lower = np.percentile(bootstrap_scores, 2.5)\n",
    "upper = np.percentile(bootstrap_scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  .632 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .632 Bootstrap is the default setting of `bootstrap_point632_score`; it tends to be overly optimistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bootstrap score 0.9673875904653735\n",
      "Score Std 0.02516454779030485\n"
     ]
    }
   ],
   "source": [
    "bootstrap_scores = bootstrap_point632_score(model, \n",
    "                                            X_train, y_train, \n",
    "                                            n_splits=200,\n",
    "                                            random_seed=123)\n",
    "print('Mean Bootstrap score', np.mean(bootstrap_scores))\n",
    "print('Score Std', np.std(bootstrap_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval: [89.47, 100.00]\n"
     ]
    }
   ],
   "source": [
    "lower = np.percentile(bootstrap_scores, 2.5)\n",
    "upper = np.percentile(bootstrap_scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  .632+ Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .632+ Boostrap method attempts to address the optimistic bias of the regular .632 Boostrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bootstrap score 0.9658029542600898\n",
      "Score Std 0.027801366648921747\n"
     ]
    }
   ],
   "source": [
    "bootstrap_scores = bootstrap_point632_score(model, X_train, y_train, \n",
    "                                            n_splits=200, \n",
    "                                            method='.632+',\n",
    "                                            random_seed=123)\n",
    "print('Mean Bootstrap score', np.mean(bootstrap_scores))\n",
    "print('Score Std', np.std(bootstrap_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval: [88.40, 100.00]\n"
     ]
    }
   ],
   "source": [
    "lower = np.percentile(bootstrap_scores, 2.5)\n",
    "upper = np.percentile(bootstrap_scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (100*lower, 100*upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
